{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_mlp_fish_market_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPhD3tBWYP9G"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTHIFLwUYP9b"
      },
      "source": [
        "### Load and scale the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOf98xw7YP9d"
      },
      "source": [
        "feature = pd.read_csv('https://raw.githubusercontent.com/ajn313/NYU2023SummerML1/main/Day5/fish_market_feature.csv')\n",
        "label = pd.read_csv('https://raw.githubusercontent.com/ajn313/NYU2023SummerML1/main/Day5/fish_market_label.csv')\n",
        "X = feature.values\n",
        "y = label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLrMTKvFm4VC"
      },
      "source": [
        "# normalize the data using sklearn's StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "Xs = scaler.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K6BT_RVm4VC"
      },
      "source": [
        "## TODO\n",
        "# split the SCALED!! data in validation and train\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(..., test_size=0.1, random_state=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BZ-u4Owm4VD"
      },
      "source": [
        "## TODO\n",
        "# print the number of data samples in the training and validation data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd-R6M1YP9s"
      },
      "source": [
        "### Build Model\n",
        "\n",
        "1) Define a model of three dense hidden layers with ReLU activation functions, plus an final dense layer. The output of the hidden layers should have 32 neurons each. \n",
        "\n",
        "2) Train the model for 2000 epochs with a batch size of 64 and a mean squared error loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlKXS0cMeMcp"
      },
      "source": [
        "## TODO\n",
        "n_epochs = 2000\n",
        "batch_size = 64\n",
        "\n",
        "model = Sequential([...])\n",
        "model.compile(...) # use the Adam optimizer\n",
        "\n",
        "# print a summary of the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRg6dJMwm4VG"
      },
      "source": [
        "## TODO\n",
        "# train the model (use the train data and validation data from above)\n",
        "history = model.fit(..., validation_data=())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-GC0wmLm4VH"
      },
      "source": [
        "## TODO\n",
        "# plot the train and validation losses on the same picture\n",
        "# make sure to label the axis and create a legend "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6kC3IVHYP-E"
      },
      "source": [
        "#### Load the testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWgUAW_mYP-F"
      },
      "source": [
        "X_test = pd.read_csv('https://raw.githubusercontent.com/ajn313/NYU2023SummerML1/main/Day5/fish_market_test_feature.csv').values\n",
        "y_test = pd.read_csv('https://raw.githubusercontent.com/ajn313/NYU2023SummerML1/main/Day5/fish_market_test_label.csv').values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6_ee1QSm4VJ"
      },
      "source": [
        "# scale the test data using the scaler above\n",
        "Xtest_s = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxrXrxmXm4VK"
      },
      "source": [
        "## TODO\n",
        "# predict the corresponding y_hat value of the test dataset (use the scaled test data)\n",
        "y_hat = model.predict(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8hiFtuwYP-P"
      },
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(np.arange(y_hat.shape[0]), y_hat, label='Prediction')\n",
        "plt.scatter(np.arange(y_test.shape[0]), y_test, label='Ground Truth')\n",
        "plt.legend()\n",
        "plt.xlabel('data no.')\n",
        "plt.ylabel('predicted value')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D2GFSHBm4VL"
      },
      "source": [
        "## TODO\n",
        "# print MSE, RMSE (root-mse), MAE on the train and test data\n",
        "# compare these results against last week's results (when we used linear/polynimial regression)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
