{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uFl5VYXPIY7D"
   },
   "source": [
    "## Breast Cancer Diagnosis via Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkFIjttvIhDs"
   },
   "source": [
    "We will use the widely-used breast cancer data set.  This data set is described [here](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin).\n",
    "\n",
    "\n",
    "\n",
    "Each sample is a collection of features that were manually recorded by a physician upon inspecting a sample of cells from fine needle aspiration. \n",
    "\n",
    "**The goal is to detect if the cells are benign or malignant.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9TNtqa-3I1K7"
   },
   "source": [
    "#### Loading and Visualizing the Data\n",
    "\n",
    "We first load the packages as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2uPPzaUIP_b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWEojdFDI8AK"
   },
   "source": [
    "Next, we load the data.  It is important to remove the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "YCBZS-xbI9gt",
    "outputId": "f215f6c3-0272-4ec1-9415-0e5c9702c23d"
   },
   "outputs": [],
   "source": [
    "names = ['id','thick','size','shape','marg','cell_size','bare',\n",
    "         'chrom','normal','mit','class']\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/' +\n",
    "                 'breast-cancer-wisconsin/breast-cancer-wisconsin.data',\n",
    "                names=names,na_values='?',header=None)\n",
    "df = df.dropna()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OYHiBO1UJEag"
   },
   "source": [
    "After loading the data, we can create a scatter plot of the data labeling the class values with different colors.  We will pick two of the features (\"size\" and \"marg\").  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "DnS-dnPIJGkc",
    "outputId": "14d1d1a5-d29b-4a21-e300-7cb710bdef8e"
   },
   "outputs": [],
   "source": [
    "# Converting to a zero-one indicator.\n",
    "yraw = np.array(df['class'])\n",
    "BEN_VAL = 2   # value in the 'class' label for benign samples\n",
    "MAL_VAL = 4   # value in the 'class' label for malignant samples\n",
    "y = (yraw == MAL_VAL).astype(int)\n",
    "Iben = (y==0)\n",
    "Imal = (y==1)\n",
    "\n",
    "# Get two predictors\n",
    "xnames =['size','marg'] \n",
    "X = np.array(df[xnames])\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(X[Imal,0],X[Imal,1],'r.')\n",
    "plt.plot(X[Iben,0],X[Iben,1],'g.')\n",
    "plt.xlabel(xnames[0], fontsize=16)\n",
    "plt.ylabel(xnames[1], fontsize=16)\n",
    "plt.ylim(0,14)\n",
    "plt.legend(['malign','benign'],loc='upper right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89PPJ0mNJIdg"
   },
   "source": [
    "The above plot is not informative, since many of the points are on top of one another.  Thus, we cannot see the relative frequency of points.  \n",
    "\n",
    "One way to improve the plot is to draw circles on each point whose size is proportional to the count of samples at that point.  We will re-use this code, so we define a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "2D1BF4bRJKro",
    "outputId": "10d68b61-cb61-4cfa-e2a9-9752b71148dd"
   },
   "outputs": [],
   "source": [
    "def plot_count(X,y):\n",
    "    \n",
    "    # Compute the bin edges for the 2d histogram\n",
    "    x0val = np.array(list(set(X[:,0]))).astype(float)\n",
    "    x1val = np.array(list(set(X[:,1]))).astype(float)\n",
    "    x0, x1 = np.meshgrid(x0val,x1val)\n",
    "    x0e= np.hstack((x0val,np.max(x0val)+1))\n",
    "    x1e= np.hstack((x1val,np.max(x1val)+1))\n",
    "\n",
    "    # Make a plot for each class\n",
    "    yval = list(set(y))\n",
    "    color = ['g','r']\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for i in range(len(yval)):\n",
    "        I = np.where(y==yval[i])[0]\n",
    "        count, x0e, x1e = np.histogram2d(X[I,0],X[I,1],[x0e,x1e])\n",
    "        x0, x1 = np.meshgrid(x0val,x1val)\n",
    "        plt.scatter(x0.ravel(), x1.ravel(), s=2*count.ravel(),alpha=0.5,\n",
    "                    c=color[i],edgecolors='none')\n",
    "    plt.ylim([0,14])\n",
    "    plt.legend(['benign','malign'], loc='upper right')\n",
    "    plt.xlabel(xnames[0], fontsize=16)\n",
    "    plt.ylabel(xnames[1], fontsize=16)\n",
    "    return plt\n",
    "\n",
    "plot_count(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aROvueqkJLdM"
   },
   "source": [
    "#  Exercise\n",
    "\n",
    "1) Based on the above plot, what would you think a good \"classifer\" using the two features could be? That is, write a rule that can classify the benign region from the malignant region.\n",
    "\n",
    "2) Define a metric function that computes TP, FP, TN, FN, the accuracy, the sensitivity and the precision.\n",
    "\n",
    "3) Try to improve your classifier given those metrics\n",
    "\n",
    "4) Use sklearn logistic regression and check each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OhtSZi3LJNPk"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement the classifier of 1) (Note that there can be multiple classifiers)\n",
    "# HINT: find the equation of the line that almost completely separates the two classes (green points from the red points in the picture above)\n",
    "#       assign values greater than this line to the \"malign\" class otherwise to the \"benign\" class.  \n",
    "def classifier(X):\n",
    "    size = X[:, 0]\n",
    "    marg = X[:, 1]\n",
    "    # TODO\n",
    "    y = ...\n",
    "    return y\n",
    "\n",
    "y_pred = classifier(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y, y_hat):\n",
    "    # TODO: 2)\n",
    "    # calculate TP, TN, FP and FN rates\n",
    "    \n",
    "    TP = np.sum((y + y_hat) == 2) # y = 1, yhat = 1\n",
    "    TN = ... # y = 0, yhat = 0\n",
    "    FP = np.sum((y - y_hat) == -1) # y = 0, yhat = 1\n",
    "    FN = ... # y = 1, yhat = 0\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "TP, TN, FP, FN = metrics(y, y_pred)\n",
    "# calculate the following metrics using TP, TN, FP, and FN\n",
    "accuracy = ...\n",
    "sensitivity = ...\n",
    "precision = ...\n",
    "print(\"TP: {}, TN: {}, FP: {}, FN: {}\".format(TP, TN, FP, FN))\n",
    "print(\"Accuracy is {}, Sensitivity is {}, Precision is {}\".format(accuracy, sensitivity, precision))\n",
    "\n",
    "# TODO: 3) try to improve your classifier and measure the performance using the metrics above\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# TODO: 4) use LogisticRegression of sklearn\n",
    "clf = LogisticRegression(random_state=0)\n",
    "\n",
    "# fit the logistic regression model\n",
    "clf.fit(...)\n",
    "\n",
    "# predict using the model\n",
    "y_pred_clf = clf.predict(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate sklearn's model according to the metrics above\n",
    "\n",
    "# TODO\n",
    "TP, TN, FP, FN = metrics(...)\n",
    "# calculate the following metrics using TP, TN, FP, and FN\n",
    "accuracy = ...\n",
    "sensitivity = ...\n",
    "precision = ...\n",
    "\n",
    "print(\"WITH SKLEARN: \")\n",
    "print(\"TP: {}, TN: {}, FP: {}, FN: {}\".format(TP, TN, FP, FN))\n",
    "print(\"Accuracy is {}, Sensitivity is {}, Precision is {}\".format(accuracy, sensitivity, precision))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MfjrSYu-WKDo"
   ],
   "include_colab_link": true,
   "name": "Breast Cancer Demo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
